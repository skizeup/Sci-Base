[
  {
    "title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "Lukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.",
    "url": "https://arxiv.org/abs/1706.03762",
    "pdf_url": "https://arxiv.org/pdf/1706.03762",
    "local_pdf": "pdfs/attention-is-all-you-need.pdf",
    "source": "arxiv",
    "tags": [
      "transformers",
      "attention",
      "nlp",
      "deep-learning"
    ],
    "doi": "10.48550/arXiv.1706.03762"
  },
  {
    "title": "Changing Data Sources in the Age of Machine Learning for Official Statistics",
    "authors": [
      "Cedric De Boom",
      "Michael Reusens"
    ],
    "year": 2023,
    "url": "http://arxiv.org/abs/2306.04338v1",
    "abstract": "Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in data sources are inevitable to occur and pose significant risks that are crucial to address in the context of machine learning for official statistics. This paper gives an overview of the main risks, liabilities, and uncertainties associated with changing data sources in the context of machine learning for official statistics. We provide a checklist of the most prevalent origins and causes of changing data sources; not only on a technical level but also regarding ownership, ethics, regulation, and public perception. Next, we highlight the repercussions of changing data sources on statistical reporting. These include technical effects such as concept drift, bias, availability, validity, accuracy and completeness, but also the neutrality and potential discontinuation of the statistical offering. We offer a few important precautionary measures, such as enhancing robustness in both data sourcing and statistical techniques, and thorough monitoring. In doing so, machine learning-based official statistics can maintain integrity, reliability, consistency, and relevance in policy-making, decision-making, and public discourse.",
    "pdf_url": "https://arxiv.org/pdf/2306.04338v1",
    "source": "arxiv",
    "tags": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "title": "DOME: Recommendations for supervised machine learning validation in biology",
    "authors": [
      "Ian Walsh",
      "Dmytro Fishman",
      "Dario Garcia-Gasulla",
      "Tiina Titma",
      "Gianluca Pollastri",
      "The ELIXIR Machine Learning focus group",
      "Jen Harrow",
      "Fotis E. Psomopoulos",
      "Silvio C. E. Tosatto"
    ],
    "year": 2020,
    "url": "http://arxiv.org/abs/2006.16189v4",
    "abstract": "Modern biology frequently relies on machine learning to provide predictions and improve decision processes. There have been recent calls for more scrutiny on machine learning performance and possible limitations. Here we present a set of community-wide recommendations aiming to help establish standards of supervised machine learning validation in biology. Adopting a structured methods description for machine learning based on data, optimization, model, evaluation (DOME) will aim to help both reviewers and readers to better understand and assess the performance and limitations of a method or outcome. The recommendations are formulated as questions to anyone wishing to pursue implementation of a machine learning algorithm. Answers to these questions can be easily included in the supplementary material of published papers.",
    "pdf_url": "https://arxiv.org/pdf/2006.16189v4",
    "source": "arxiv",
    "tags": [
      "q-bio.OT",
      "cs.LG"
    ]
  },
  {
    "title": "Learning Curves for Decision Making in Supervised Machine Learning: A Survey",
    "authors": [
      "Felix Mohr",
      "Jan N. van Rijn"
    ],
    "year": 2022,
    "url": "http://arxiv.org/abs/2201.12150v2",
    "abstract": "Learning curves are a concept from social sciences that has been adopted in the context of machine learning to assess the performance of a learning algorithm with respect to a certain resource, e.g., the number of training examples or the number of training iterations. Learning curves have important applications in several machine learning contexts, most notably in data acquisition, early stopping of model training, and model selection. For instance, learning curves can be used to model the performance of the combination of an algorithm and its hyperparameter configuration, providing insights into their potential suitability at an early stage and often expediting the algorithm selection process. Various learning curve models have been proposed to use learning curves for decision making. Some of these models answer the binary decision question of whether a given algorithm at a certain budget will outperform a certain reference performance, whereas more complex models predict the entire learning curve of an algorithm. We contribute a framework that categorises learning curve approaches using three criteria: the decision-making situation they address, the intrinsic learning curve question they answer and the type of resources they use. We survey papers from the literature and classify them into this framework.",
    "pdf_url": "https://arxiv.org/pdf/2201.12150v2",
    "source": "arxiv",
    "tags": [
      "cs.LG"
    ],
    "doi": "10.1007/s10994-024-06619-7"
  }
]