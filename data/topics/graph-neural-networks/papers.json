[
  {
    "title": "The Deep Arbitrary Polynomial Chaos Neural Network or how Deep Artificial Neural Networks could benefit from Data-Driven Homogeneous Chaos Theory",
    "authors": [
      "Sergey Oladyshkin",
      "Timothy Praditia",
      "Ilja Kröker",
      "Farid Mohammadi",
      "Wolfgang Nowak",
      "Sebastian Otte"
    ],
    "year": 2023,
    "url": "http://arxiv.org/abs/2306.14753v1",
    "abstract": "Artificial Intelligence and Machine learning have been widely used in various fields of mathematical computing, physical modeling, computational science, communication science, and stochastic analysis. Approaches based on Deep Artificial Neural Networks (DANN) are very popular in our days. Depending on the learning task, the exact form of DANNs is determined via their multi-layer architecture, activation functions and the so-called loss function. However, for a majority of deep learning approaches based on DANNs, the kernel structure of neural signal processing remains the same, where the node response is encoded as a linear superposition of neural activity, while the non-linearity is triggered by the activation functions. In the current paper, we suggest to analyze the neural signal processing in DANNs from the point of view of homogeneous chaos theory as known from polynomial chaos expansion (PCE). From the PCE perspective, the (linear) response on each node of a DANN could be seen as a $1^{st}$ degree multi-variate polynomial of single neurons from the previous layer, i.e. linear weighted sum of monomials. From this point of view, the conventional DANN structure relies implicitly (but erroneously) on a Gaussian distribution of neural signals. Additionally, this view revels that by design DANNs do not necessarily fulfill any orthogonality or orthonormality condition for a majority of data-driven applications. Therefore, the prevailing handling of neural signals in DANNs could lead to redundant representation as any neural signal could contain some partial information from other neural signals. To tackle that challenge, we suggest to employ the data-driven generalization of PCE theory known as arbitrary polynomial chaos (aPC) to construct a corresponding multi-variate orthonormal representations on each node of a DANN to obtain Deep arbitrary polynomial chaos neural networks.",
    "pdf_url": "https://arxiv.org/pdf/2306.14753v1",
    "source": "arxiv",
    "tags": [
      "cs.NE",
      "stat.ML"
    ],
    "doi": "10.1016/j.neunet.2023.06.036"
  },
  {
    "title": "Learning Active Subspaces and Discovering Important Features with Gaussian Radial Basis Functions Neural Networks",
    "authors": [
      "Danny D'Agostino",
      "Ilija Ilievski",
      "Christine Annette Shoemaker"
    ],
    "year": 2023,
    "url": "http://arxiv.org/abs/2307.05639v2",
    "abstract": "Providing a model that achieves a strong predictive performance and is simultaneously interpretable by humans is one of the most difficult challenges in machine learning research due to the conflicting nature of these two objectives. To address this challenge, we propose a modification of the radial basis function neural network model by equipping its Gaussian kernel with a learnable precision matrix. We show that precious information is contained in the spectrum of the precision matrix that can be extracted once the training of the model is completed. In particular, the eigenvectors explain the directions of maximum sensitivity of the model revealing the active subspace and suggesting potential applications for supervised dimensionality reduction. At the same time, the eigenvectors highlight the relationship in terms of absolute variation between the input and the latent variables, thereby allowing us to extract a ranking of the input variables based on their importance to the prediction task enhancing the model interpretability. We conducted numerical experiments for regression, classification, and feature selection tasks, comparing our model against popular machine learning models, the state-of-the-art deep learning-based embedding feature selection techniques, and a transformer model for tabular data. Our results demonstrate that the proposed model does not only yield an attractive prediction performance compared to the competitors but also provides meaningful and interpretable results that potentially could assist the decision-making process in real-world applications. A PyTorch implementation of the model is available on GitHub at the following link. https://github.com/dannyzx/Gaussian-RBFNN",
    "pdf_url": "https://arxiv.org/pdf/2307.05639v2",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ],
    "doi": "10.1016/j.neunet.2024.106335"
  },
  {
    "title": "MECCH: Metapath Context Convolution-based Heterogeneous Graph Neural Networks",
    "authors": [
      "Xinyu Fu",
      "Irwin King"
    ],
    "year": 2022,
    "url": "http://arxiv.org/abs/2211.12792v2",
    "abstract": "Heterogeneous graph neural networks (HGNNs) were proposed for representation learning on structural data with multiple types of nodes and edges. To deal with the performance degradation issue when HGNNs become deep, researchers combine metapaths into HGNNs to associate nodes closely related in semantics but far apart in the graph. However, existing metapath-based models suffer from either information loss or high computation costs. To address these problems, we present a novel Metapath Context Convolution-based Heterogeneous Graph Neural Network (MECCH). MECCH leverages metapath contexts, a new kind of graph structure that facilitates lossless node information aggregation while avoiding any redundancy. Specifically, MECCH applies three novel components after feature preprocessing to extract comprehensive information from the input graph efficiently: (1) metapath context construction, (2) metapath context encoder, and (3) convolutional metapath fusion. Experiments on five real-world heterogeneous graph datasets for node classification and link prediction show that MECCH achieves superior prediction accuracy compared with state-of-the-art baselines with improved computational efficiency.",
    "pdf_url": "https://arxiv.org/pdf/2211.12792v2",
    "source": "arxiv",
    "tags": [
      "cs.LG"
    ],
    "doi": "10.1016/j.neunet.2023.11.030"
  },
  {
    "title": "Hierarchical Attentional Hybrid Neural Networks for Document Classification",
    "authors": [
      "Jader Abreu",
      "Luis Fred",
      "David Macêdo",
      "Cleber Zanchettin"
    ],
    "year": 2019,
    "url": "http://arxiv.org/abs/1901.06610v2",
    "abstract": "Document classification is a challenging task with important applications. The deep learning approaches to the problem have gained much attention recently. Despite the progress, the proposed models do not incorporate the knowledge of the document structure in the architecture efficiently and not take into account the contexting importance of words and sentences. In this paper, we propose a new approach based on a combination of convolutional neural networks, gated recurrent units, and attention mechanisms for document classification tasks. The main contribution of this work is the use of convolution layers to extract more meaningful, generalizable and abstract features by the hierarchical representation. The proposed method in this paper improves the results of the current attention-based approaches for document classification.",
    "pdf_url": "https://arxiv.org/pdf/1901.06610v2",
    "source": "arxiv",
    "tags": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "doi": "10.1007/978-3-030-30493-5_39"
  },
  {
    "title": "A Neural Network-Evolutionary Computational Framework for Remaining Useful Life Estimation of Mechanical Systems",
    "authors": [
      "David Laredo",
      "Zhaoyin Chen",
      "Oliver Schütze",
      "Jian-Qiao Sun"
    ],
    "year": 2019,
    "url": "http://arxiv.org/abs/1905.05918v1",
    "abstract": "This paper presents a framework for estimating the remaining useful life (RUL) of mechanical systems. The framework consists of a multi-layer perceptron and an evolutionary algorithm for optimizing the data-related parameters. The framework makes use of a strided time window to estimate the RUL for mechanical components. Tuning the data-related parameters can become a very time consuming task. The framework presented here automatically reshapes the data such that the efficiency of the model is increased. Furthermore, the complexity of the model is kept low, e.g. neural networks with few hidden layers and few neurons at each layer. Having simple models has several advantages like short training times and the capacity of being in environments with limited computational resources such as embedded systems. The proposed method is evaluated on the publicly available C-MAPSS dataset, its accuracy is compared against other state-of-the art methods for the same dataset.",
    "pdf_url": "https://arxiv.org/pdf/1905.05918v1",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ],
    "doi": "10.1016/j.neunet.2019.04.016"
  },
  {
    "title": "A Review on Neural Network Models of Schizophrenia and Autism Spectrum Disorder",
    "authors": [
      "Pablo Lanillos",
      "Daniel Oliva",
      "Anja Philippsen",
      "Yuichi Yamashita",
      "Yukie Nagai",
      "Gordon Cheng"
    ],
    "year": 2019,
    "url": "http://arxiv.org/abs/1906.10015v2",
    "abstract": "This survey presents the most relevant neural network models of autism spectrum disorder and schizophrenia, from the first connectionist models to recent deep network architectures. We analyzed and compared the most representative symptoms with its neural model counterpart, detailing the alteration introduced in the network that generates each of the symptoms, and identifying their strengths and weaknesses. We additionally cross-compared Bayesian and free-energy approaches, as they are widely applied to modeling psychiatric disorders and share basic mechanisms with neural networks. Models of schizophrenia mainly focused on hallucinations and delusional thoughts using neural dysconnections or inhibitory imbalance as the predominating alteration. Models of autism rather focused on perceptual difficulties, mainly excessive attention to environment details, implemented as excessive inhibitory connections or increased sensory precision. We found an excessive tight view of the psychopathologies around one specific and simplified effect, usually constrained to the technical idiosyncrasy of the used network architecture. Recent theories and evidence on sensorimotor integration and body perception combined with modern neural network architectures could offer a broader and novel spectrum to approach these psychopathologies. This review emphasizes the power of artificial neural networks for modeling some symptoms of neurological disorders but also calls for further developing these techniques in the field of computational psychiatry.",
    "pdf_url": "https://arxiv.org/pdf/1906.10015v2",
    "source": "arxiv",
    "tags": [
      "q-bio.NC",
      "cs.AI",
      "cs.NE"
    ],
    "doi": "10.1016/j.neunet.2019.10.014"
  },
  {
    "title": "Continual Learning for Recurrent Neural Networks: an Empirical Evaluation",
    "authors": [
      "Andrea Cossu",
      "Antonio Carta",
      "Vincenzo Lomonaco",
      "Davide Bacciu"
    ],
    "year": 2021,
    "url": "http://arxiv.org/abs/2103.07492v4",
    "abstract": "Learning continuously during all model lifetime is fundamental to deploy machine learning solutions robust to drifts in the data distribution. Advances in Continual Learning (CL) with recurrent neural networks could pave the way to a large number of applications where incoming data is non stationary, like natural language processing and robotics. However, the existing body of work on the topic is still fragmented, with approaches which are application-specific and whose assessment is based on heterogeneous learning protocols and datasets. In this paper, we organize the literature on CL for sequential data processing by providing a categorization of the contributions and a review of the benchmarks. We propose two new benchmarks for CL with sequential data based on existing datasets, whose characteristics resemble real-world applications. We also provide a broad empirical evaluation of CL and Recurrent Neural Networks in class-incremental scenario, by testing their ability to mitigate forgetting with a number of different strategies which are not specific to sequential data processing. Our results highlight the key role played by the sequence length and the importance of a clear specification of the CL scenario.",
    "pdf_url": "https://arxiv.org/pdf/2103.07492v4",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "cs.AI"
    ],
    "doi": "10.1016/j.neunet.2021.07.021"
  },
  {
    "title": "Towards Dropout Training for Convolutional Neural Networks",
    "authors": [
      "Haibing Wu",
      "Xiaodong Gu"
    ],
    "year": 2015,
    "url": "http://arxiv.org/abs/1512.00242v1",
    "abstract": "Recently, dropout has seen increasing use in deep learning. For deep convolutional neural networks, dropout is known to work well in fully-connected layers. However, its effect in convolutional and pooling layers is still not clear. This paper demonstrates that max-pooling dropout is equivalent to randomly picking activation based on a multinomial distribution at training time. In light of this insight, we advocate employing our proposed probabilistic weighted pooling, instead of commonly used max-pooling, to act as model averaging at test time. Empirical evidence validates the superiority of probabilistic weighted pooling. We also empirically show that the effect of convolutional dropout is not trivial, despite the dramatically reduced possibility of over-fitting due to the convolutional architecture. Elaborately designing dropout training simultaneously in max-pooling and fully-connected layers, we achieve state-of-the-art performance on MNIST, and very competitive results on CIFAR-10 and CIFAR-100, relative to other approaches without data augmentation. Finally, we compare max-pooling dropout and stochastic pooling, both of which introduce stochasticity based on multinomial distributions at pooling stage.",
    "pdf_url": "https://arxiv.org/pdf/1512.00242v1",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "cs.CV",
      "cs.NE"
    ],
    "doi": "10.1016/j.neunet.2015.07.007"
  },
  {
    "title": "Development of a sensory-neural network for medical diagnosing",
    "authors": [
      "Igor Grabec",
      "Eva Švegl",
      "Mihael Sok"
    ],
    "year": 2018,
    "url": "http://arxiv.org/abs/1807.02477v1",
    "abstract": "Performance of a sensory-neural network developed for diagnosing of diseases is described. Information about patient's condition is provided by answers to the questionnaire. Questions correspond to sensors generating signals when patients acknowledge symptoms. These signals excite neurons in which characteristics of the diseases are represented by synaptic weights associated with indicators of symptoms. The disease corresponding to the most excited neuron is proposed as the result of diagnosing. Its reliability is estimated by the likelihood defined by the ratio of excitation of the most excited neuron and the complete neural network.",
    "pdf_url": "https://arxiv.org/pdf/1807.02477v1",
    "source": "arxiv",
    "tags": [
      "cs.NE"
    ]
  },
  {
    "title": "Acute Lymphoblastic Leukemia Detection Using Hypercomplex-Valued Convolutional Neural Networks",
    "authors": [
      "Guilherme Vieira",
      "Marcos Eduardo Valle"
    ],
    "year": 2022,
    "url": "http://arxiv.org/abs/2205.13273v1",
    "abstract": "This paper features convolutional neural networks defined on hypercomplex algebras applied to classify lymphocytes in blood smear digital microscopic images. Such classification is helpful for the diagnosis of acute lymphoblast leukemia (ALL), a type of blood cancer. We perform the classification task using eight hypercomplex-valued convolutional neural networks (HvCNNs) along with real-valued convolutional networks. Our results show that HvCNNs perform better than the real-valued model, showcasing higher accuracy with a much smaller number of parameters. Moreover, we found that HvCNNs based on Clifford algebras processing HSV-encoded images attained the highest observed accuracies. Precisely, our HvCNN yielded an average accuracy rate of 96.6% using the ALL-IDB2 dataset with a 50% train-test split, a value extremely close to the state-of-the-art models but using a much simpler architecture with significantly fewer parameters.",
    "pdf_url": "https://arxiv.org/pdf/2205.13273v1",
    "source": "arxiv",
    "tags": [
      "cs.CV",
      "cs.LG",
      "cs.NE",
      "eess.IV"
    ],
    "doi": "10.1109/IJCNN55064.2022.9892036"
  },
  {
    "title": "Optimal hierarchical modular topologies for producing limited sustained activation of neural networks",
    "authors": [
      "Marcus Kaiser",
      "Claus C. Hilgetag"
    ],
    "year": 2010,
    "url": "http://arxiv.org/abs/1003.3081v1",
    "abstract": "An essential requirement for the representation of functional patterns in complex neural networks, such as the mammalian cerebral cortex, is the existence of stable regimes of network activation, typically arising from a limited parameter range. In this range of limited sustained activity (LSA), the activity of neural populations in the network persists between the extremes of either quickly dying out or activating the whole network. Hierarchical modular networks were previously found to show a wider parameter range for LSA than random or small-world networks not possessing hierarchical organization or multiple modules. Here we explored how variation in the number of hierarchical levels and modules per level influenced network dynamics and occurrence of LSA. We tested hierarchical configurations of different network sizes, approximating the large-scale networks linking cortical columns in one hemisphere of the rat, cat, or macaque monkey brain. Scaling of the network size affected the number of hierarchical levels and modules in the optimal networks, also depending on whether global edge density or the numbers of connections per node were kept constant. For constant edge density, only few network configurations, possessing an intermediate number of levels and a large number of modules, led to a large range of LSA independent of brain size. For a constant number of node connections, there was a trend for optimal configurations in larger-size networks to possess a larger number of hierarchical levels or more modules. These results may help to explain the trend to greater network complexity apparent in larger brains and may indicate that this complexity is required for maintaining stable levels of neural activation.",
    "pdf_url": "https://arxiv.org/pdf/1003.3081v1",
    "source": "arxiv",
    "tags": [
      "q-bio.NC",
      "cond-mat.dis-nn",
      "physics.soc-ph"
    ],
    "doi": "10.3389/fninf.2010.00008"
  },
  {
    "title": "Spiking Inception Module for Multi-layer Unsupervised Spiking Neural Networks",
    "authors": [
      "Mingyuan Meng",
      "Xingyu Yang",
      "Shanlin Xiao",
      "Zhiyi Yu"
    ],
    "year": 2020,
    "url": "http://arxiv.org/abs/2001.10696v5",
    "abstract": "Spiking Neural Network (SNN), as a brain-inspired approach, is attracting attention due to its potential to produce ultra-high-energy-efficient hardware. Competitive learning based on Spike-Timing-Dependent Plasticity (STDP) is a popular method to train an unsupervised SNN. However, previous unsupervised SNNs trained through this method are limited to a shallow network with only one learnable layer and cannot achieve satisfactory results when compared with multi-layer SNNs. In this paper, we eased this limitation by: 1)We proposed a Spiking Inception (Sp-Inception) module, inspired by the Inception module in the Artificial Neural Network (ANN) literature. This module is trained through STDP-based competitive learning and outperforms the baseline modules on learning capability, learning efficiency, and robustness. 2)We proposed a Pooling-Reshape-Activate (PRA) layer to make the Sp-Inception module stackable. 3)We stacked multiple Sp-Inception modules to construct multi-layer SNNs. Our algorithm outperforms the baseline algorithms on the hand-written digit classification task, and reaches state-of-the-art results on the MNIST dataset among the existing unsupervised SNNs.",
    "pdf_url": "https://arxiv.org/pdf/2001.10696v5",
    "source": "arxiv",
    "tags": [
      "cs.NE",
      "cs.LG",
      "q-bio.NC"
    ],
    "doi": "10.1109/IJCNN48605.2020.9207161"
  },
  {
    "title": "Improving Generalization of Deep Neural Networks by Leveraging Margin Distribution",
    "authors": [
      "Shen-Huan Lyu",
      "Lu Wang",
      "Zhi-Hua Zhou"
    ],
    "year": 2018,
    "url": "http://arxiv.org/abs/1812.10761v3",
    "abstract": "Recent research has used margin theory to analyze the generalization performance for deep neural networks (DNNs). The existed results are almost based on the spectrally-normalized minimum margin. However, optimizing the minimum margin ignores a mass of information about the entire margin distribution, which is crucial to generalization performance. In this paper, we prove a generalization upper bound dominated by the statistics of the entire margin distribution. Compared with the minimum margin bounds, our bound highlights an important measure for controlling the complexity, which is the ratio of the margin standard deviation to the expected margin. We utilize a convex margin distribution loss function on the deep neural networks to validate our theoretical results by optimizing the margin ratio. Experiments and visualizations confirm the effectiveness of our approach and the correlation between generalization gap and margin ratio.",
    "pdf_url": "https://arxiv.org/pdf/1812.10761v3",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "stat.ML"
    ],
    "doi": "10.1016/j.neunet.2022.03.019."
  },
  {
    "title": "Transformers are Graph Neural Networks",
    "authors": [
      "Chaitanya K. Joshi"
    ],
    "year": 2025,
    "url": "http://arxiv.org/abs/2506.22084v1",
    "abstract": "We establish connections between the Transformer architecture, originally introduced for natural language processing, and Graph Neural Networks (GNNs) for representation learning on graphs. We show how Transformers can be viewed as message passing GNNs operating on fully connected graphs of tokens, where the self-attention mechanism capture the relative importance of all tokens w.r.t. each-other, and positional encodings provide hints about sequential ordering or structure. Thus, Transformers are expressive set processing networks that learn relationships among input elements without being constrained by apriori graphs. Despite this mathematical connection to GNNs, Transformers are implemented via dense matrix operations that are significantly more efficient on modern hardware than sparse message passing. This leads to the perspective that Transformers are GNNs currently winning the hardware lottery.",
    "pdf_url": "https://arxiv.org/pdf/2506.22084v1",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Fast and Deep Graph Neural Networks",
    "authors": [
      "Claudio Gallicchio",
      "Alessio Micheli"
    ],
    "year": 2019,
    "url": "http://arxiv.org/abs/1911.08941v1",
    "abstract": "We address the efficiency issue for the construction of a deep graph neural network (GNN). The approach exploits the idea of representing each input graph as a fixed point of a dynamical system (implemented through a recurrent neural network), and leverages a deep architectural organization of the recurrent units. Efficiency is gained by many aspects, including the use of small and very sparse networks, where the weights of the recurrent units are left untrained under the stability condition introduced in this work. This can be viewed as a way to study the intrinsic power of the architecture of a deep GNN, and also to provide insights for the set-up of more complex fully-trained models. Through experimental results, we show that even without training of the recurrent connections, the architecture of small deep GNN is surprisingly able to achieve or improve the state-of-the-art performance on a significant set of tasks in the field of graphs classification.",
    "pdf_url": "https://arxiv.org/pdf/1911.08941v1",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "math.DS",
      "stat.ML"
    ]
  },
  {
    "title": "Multiclass Graph-Based Large Margin Classifiers: Unified Approach for Support Vectors and Neural Networks",
    "authors": [
      "Vítor M. Hanriot",
      "Luiz C. B. Torres",
      "Antônio P. Braga"
    ],
    "year": 2025,
    "url": "http://arxiv.org/abs/2512.13410v1",
    "abstract": "While large margin classifiers are originally an outcome of an optimization framework, support vectors (SVs) can be obtained from geometric approaches. This article presents advances in the use of Gabriel graphs (GGs) in binary and multiclass classification problems. For Chipclass, a hyperparameter-less and optimization-less GG-based binary classifier, we discuss how activation functions and support edge (SE)-centered neurons affect the classification, proposing smoother functions and structural SV (SSV)-centered neurons to achieve margins with low probabilities and smoother classification contours. We extend the neural network architecture, which can be trained with backpropagation with a softmax function and a cross-entropy loss, or by solving a system of linear equations. A new subgraph-/distance-based membership function for graph regularization is also proposed, along with a new GG recomputation algorithm that is less computationally expensive than the standard approach. Experimental results with the Friedman test show that our method was better than previous GG-based classifiers and statistically equivalent to tree-based models.",
    "pdf_url": "https://arxiv.org/pdf/2512.13410v1",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "stat.ML"
    ],
    "doi": "10.1109/TNNLS.2024.3420227"
  },
  {
    "title": "Dual Accuracy-Quality-Driven Neural Network for Prediction Interval Generation",
    "authors": [
      "Giorgio Morales",
      "John W. Sheppard"
    ],
    "year": 2022,
    "url": "http://arxiv.org/abs/2212.06370v4",
    "abstract": "Accurate uncertainty quantification is necessary to enhance the reliability of deep learning models in real-world applications. In the case of regression tasks, prediction intervals (PIs) should be provided along with the deterministic predictions of deep learning models. Such PIs are useful or \"high-quality\" as long as they are sufficiently narrow and capture most of the probability density. In this paper, we present a method to learn prediction intervals for regression-based neural networks automatically in addition to the conventional target predictions. In particular, we train two companion neural networks: one that uses one output, the target estimate, and another that uses two outputs, the upper and lower bounds of the corresponding PI. Our main contribution is the design of a novel loss function for the PI-generation network that takes into account the output of the target-estimation network and has two optimization objectives: minimizing the mean prediction interval width and ensuring the PI integrity using constraints that maximize the prediction interval probability coverage implicitly. Furthermore, we introduce a self-adaptive coefficient that balances both objectives within the loss function, which alleviates the task of fine-tuning. Experiments using a synthetic dataset, eight benchmark datasets, and a real-world crop yield prediction dataset showed that our method was able to maintain a nominal probability coverage and produce significantly narrower PIs without detriment to its target estimation accuracy when compared to those PIs generated by three state-of-the-art neural-network-based methods. In other words, our method was shown to produce higher-quality PIs.",
    "pdf_url": "https://arxiv.org/pdf/2212.06370v4",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "stat.ML"
    ],
    "doi": "10.1109/TNNLS.2023.3339470"
  },
  {
    "title": "Modern graph neural networks do worse than classical greedy algorithms in solving combinatorial optimization problems like maximum independent set",
    "authors": [
      "Maria Chiara Angelini",
      "Federico Ricci-Tersenghi"
    ],
    "year": 2022,
    "url": "http://arxiv.org/abs/2206.13211v2",
    "abstract": "The recent work ``Combinatorial Optimization with Physics-Inspired Graph Neural Networks'' [Nat Mach Intell 4 (2022) 367] introduces a physics-inspired unsupervised Graph Neural Network (GNN) to solve combinatorial optimization problems on sparse graphs. To test the performances of these GNNs, the authors of the work show numerical results for two fundamental problems: maximum cut and maximum independent set (MIS). They conclude that \"the graph neural network optimizer performs on par or outperforms existing solvers, with the ability to scale beyond the state of the art to problems with millions of variables.\" In this comment, we show that a simple greedy algorithm, running in almost linear time, can find solutions for the MIS problem of much better quality than the GNN. The greedy algorithm is faster by a factor of $10^4$ with respect to the GNN for problems with a million variables. We do not see any good reason for solving the MIS with these GNN, as well as for using a sledgehammer to crack nuts. In general, many claims of superiority of neural networks in solving combinatorial problems are at risk of being not solid enough, since we lack standard benchmarks based on really hard problems. We propose one of such hard benchmarks, and we hope to see future neural network optimizers tested on these problems before any claim of superiority is made.",
    "pdf_url": "https://arxiv.org/pdf/2206.13211v2",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI",
      "math.OC"
    ],
    "doi": "10.1038/s42256-022-00589-y"
  },
  {
    "title": "A Recurrent Probabilistic Neural Network with Dimensionality Reduction Based on Time-series Discriminant Component Analysis",
    "authors": [
      "Hideaki Hayashi",
      "Taro Shibanoki",
      "Keisuke Shima",
      "Yuichi Kurita",
      "Toshio Tsuji"
    ],
    "year": 2019,
    "url": "http://arxiv.org/abs/1911.06009v1",
    "abstract": "This paper proposes a probabilistic neural network developed on the basis of time-series discriminant component analysis (TSDCA) that can be used to classify high-dimensional time-series patterns. TSDCA involves the compression of high-dimensional time series into a lower-dimensional space using a set of orthogonal transformations and the calculation of posterior probabilities based on a continuous-density hidden Markov model with a Gaussian mixture model expressed in the reduced-dimensional space. The analysis can be incorporated into a neural network, which is named a time-series discriminant component network (TSDCN), so that parameters of dimensionality reduction and classification can be obtained simultaneously as network coefficients according to a backpropagation through time-based learning algorithm with the Lagrange multiplier method. The TSDCN is considered to enable high-accuracy classification of high-dimensional time-series patterns and to reduce the computation time taken for network training. The validity of the TSDCN is demonstrated for high-dimensional artificial data and EEG signals in the experiments conducted during the study.",
    "pdf_url": "https://arxiv.org/pdf/1911.06009v1",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "stat.ML"
    ],
    "doi": "10.1109/TNNLS.2015.2400448"
  },
  {
    "title": "Missing Data Imputation with Adversarially-trained Graph Convolutional Networks",
    "authors": [
      "Indro Spinelli",
      "Simone Scardapane",
      "Aurelio Uncini"
    ],
    "year": 2019,
    "url": "http://arxiv.org/abs/1905.01907v2",
    "abstract": "Missing data imputation (MDI) is a fundamental problem in many scientific disciplines. Popular methods for MDI use global statistics computed from the entire data set (e.g., the feature-wise medians), or build predictive models operating independently on every instance. In this paper we propose a more general framework for MDI, leveraging recent work in the field of graph neural networks (GNNs). We formulate the MDI task in terms of a graph denoising autoencoder, where each edge of the graph encodes the similarity between two patterns. A GNN encoder learns to build intermediate representations for each example by interleaving classical projection layers and locally combining information between neighbors, while another decoding GNN learns to reconstruct the full imputed data set from this intermediate embedding. In order to speed-up training and improve the performance, we use a combination of multiple losses, including an adversarial loss implemented with the Wasserstein metric and a gradient penalty. We also explore a few extensions to the basic architecture involving the use of residual connections between layers, and of global statistics computed from the data set to improve the accuracy. On a large experimental evaluation, we show that our method robustly outperforms state-of-the-art approaches for MDI, especially for large percentages of missing values.",
    "pdf_url": "https://arxiv.org/pdf/1905.01907v2",
    "source": "arxiv",
    "tags": [
      "cs.LG",
      "stat.ML"
    ],
    "doi": "10.1016/j.neunet.2020.06.005"
  }
]