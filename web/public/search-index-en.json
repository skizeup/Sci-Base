[{"type":"topic","title":"Bioinformatique","description":"La bioinformatique se situe à l'intersection de la biologie, de l'informatique et des mathématiques. Elle développe des méthodes computationnelles pour analyser les données biologiques : séquences ADN","url":"/en/topics/bioinformatics","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","level":"intermediaire"},{"type":"paper","title":"Bayesian uncertainty analysis for complex systems biology models: emulation, global parameter searches and evaluation of gene functions","description":"Background: Many mathematical models have now been employed across every area of systems biology. These models increasingly involve large numbers of unknown parameters, have complex structure which ca","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["q-bio.MN","q-bio.CB","q-bio.QM","stat.AP","stat.ME"]},{"type":"paper","title":"PRIMRose: Insights into the Per-Residue Energy Metrics of Proteins with Double InDel Mutations using Deep Learning","description":"Understanding how protein mutations affect protein structure is essential for advancements in computational biology and bioinformatics. We introduce PRIMRose, a novel approach that predicts energy val","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["q-bio.BM","cs.AI","cs.LG","cs.NE","q-bio.QM"]},{"type":"paper","title":"Deciphering neural circuits for Caenorhabditis elegans behavior by computations and perturbations to genome and connectome","description":"Caenorhabditis elegans nematode worms are the only animals with the known detailed neural connectivity diagram, well characterized genomics, and relatively simple quantifiable behavioral output. With ","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["q-bio.NC","q-bio.GN","q-bio.QM"]},{"type":"paper","title":"Deep Learning in Bioinformatics","description":"In the era of big data, transformation of biomedical big data into valuable knowledge has been one of the most important challenges in bioinformatics. Deep learning has advanced rapidly since the earl","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["cs.LG","q-bio.GN"]},{"type":"paper","title":"Universally Sloppy Parameter Sensitivities in Systems Biology","description":"Quantitative computational models play an increasingly important role in modern biology. Such models typically involve many free parameters, and assigning their values is often a substantial obstacle ","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["q-bio.QM","q-bio.MN"]},{"type":"paper","title":"Big Data Analytics in Bioinformatics: A Machine Learning Perspective","description":"Bioinformatics research is characterized by voluminous and incremental datasets and complex data analytics methods. The machine learning methods used in bioinformatics are iterative and parallel. Thes","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["cs.CE","cs.LG"]},{"type":"paper","title":"Fighting against uncertainty: An essential issue in bioinformatics","description":"Many bioinformatics problems, such as sequence alignment, gene prediction, phylogenetic tree estimation and RNA secondary structure prediction, are often affected by the \"uncertainty\" of a solution; t","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["q-bio.QM","q-bio.BM","q-bio.GN"]},{"type":"paper","title":"Evaluation of Galaxy as a User-friendly Bioinformatics Tool for Enhancing Clinical Diagnostics in Genetics Laboratories","description":"Bioinformatics platforms have significantly changed clinical diagnostics by facilitating the analysis of genomic data, thereby advancing personalized medicine and improving patient care. This study ex","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["cs.HC"]},{"type":"paper","title":"ISLAND: In-Silico Prediction of Proteins Binding Affinity Using Sequence Descriptors","description":"Determination of binding affinity of proteins in the formation of protein complexes requires sophisticated, expensive and time-consuming experimentation which can be replaced with computational method","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["q-bio.QM","cs.LG"]},{"type":"paper","title":"A Novel Approach for Protein Structure Prediction","description":"The idea of this project is to study the protein structure and sequence relationship using the hidden markov model and artificial neural network. In this context we have assumed two hidden markov mode","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["cs.LG","q-bio.BM"]},{"type":"paper","title":"MUST-CNN: A Multilayer Shift-and-Stitch Deep Convolutional Architecture for Sequence-based Protein Structure Prediction","description":"Predicting protein properties such as solvent accessibility and secondary structure from its primary amino acid sequence is an important task in bioinformatics. Recently, a few deep learning models ha","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["cs.LG"]},{"type":"paper","title":"AlphaFold predicts the most complex protein knot and composite protein knots","description":"The computer artificial intelligence system AlphaFold has recently predicted previously unknown three-dimensional structures of thousands of proteins. Focusing on the subset with high-confidence score","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["q-bio.BM","cond-mat.soft","physics.bio-ph"]},{"type":"paper","title":"Protein-to-genome alignment with miniprot","description":"Motivation: Protein-to-genome alignment is critical to annotating genes in non-model organisms. While there are a few tools for this purpose, all of them were developed over ten years ago and did not ","url":"/en/topics/bioinformatics/papers","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","tags":["q-bio.GN"]},{"type":"quiz","title":"Quiz — Bioinformatique","description":"10 questions to test your knowledge on Bioinformatique","url":"/en/topics/bioinformatics/quiz","topicSlug":"bioinformatics","topicTitle":"Bioinformatique","level":"intermediaire"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/a-novel-approach-for-protein-structure-prediction","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/alphafold-predicts-the-most-complex-protein-knot-and-composite-protein-knots","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/bayesian-uncertainty-analysis-for-complex-systems-biology-models-emulation-global-parameter-searches-and-evaluation-of-gene-functions","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/big-data-analytics-in-bioinformatics-a-machine-learning-perspective","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/deciphering-neural-circuits-for-caenorhabditis-elegans-behavior-by-computations-and-perturbations-to-genome-and-connectome","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/deep-learning-in-bioinformatics","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/evaluation-of-galaxy-as-a-user-friendly-bioinformatics-tool-for-enhancing-clinical-diagnostics-in-genetics-laboratories","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/fighting-against-uncertainty-an-essential-issue-in-bioinformatics","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/island-in-silico-prediction-of-proteins-binding-affinity-using-sequence-descriptors","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/must-cnn-a-multilayer-shift-and-stitch-deep-convolutional-architecture-for-sequence-based-protein-structure-prediction","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/primrose-insights-into-the-per-residue-energy-metrics-of-proteins-with-double-indel-mutations-using-deep-learning","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/protein-to-genome-alignment-with-miniprot","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Bioinformatique","url":"/en/topics/bioinformatics/papers/universally-sloppy-parameter-sensitivities-in-systems-biology","topicSlug":"bioinformatics","topicTitle":"Bioinformatique"},{"type":"topic","title":"Computer Vision","description":"La vision par ordinateur (computer vision) est le domaine de l'IA qui permet aux machines d'**interpréter et comprendre le contenu visuel** : images, vidéos, flux de caméras. L'objectif est d'extraire","url":"/en/topics/computer-vision","topicSlug":"computer-vision","topicTitle":"Computer Vision","level":"intermediaire"},{"type":"paper","title":"Very Deep Convolutional Networks for Large-Scale Image Recognition","description":"In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of in","url":"/en/topics/computer-vision/papers","topicSlug":"computer-vision","topicTitle":"Computer Vision","tags":["vgg","cnn","imagenet","classification"]},{"type":"paper","title":"You Only Look Once: Unified, Real-Time Object Detection","description":"We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially","url":"/en/topics/computer-vision/papers","topicSlug":"computer-vision","topicTitle":"Computer Vision","tags":["yolo","object-detection","real-time"]},{"type":"paper","title":"Mask R-CNN","description":"We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality ","url":"/en/topics/computer-vision/papers","topicSlug":"computer-vision","topicTitle":"Computer Vision","tags":["instance-segmentation","object-detection","mask-rcnn"]},{"type":"paper","title":"U-Net: Convolutional Networks for Biomedical Image Segmentation","description":"There is large consent that successful training of deep networks requires many thousands of annotated training samples. In this paper, we present a network and training strategy that relies on the str","url":"/en/topics/computer-vision/papers","topicSlug":"computer-vision","topicTitle":"Computer Vision","tags":["unet","segmentation","medical-imaging"]},{"type":"paper","title":"High-Resolution Image Synthesis with Latent Diffusion Models","description":"By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models can achieve state-of-the-art synthesis results on image data. We apply diffusion mo","url":"/en/topics/computer-vision/papers","topicSlug":"computer-vision","topicTitle":"Computer Vision","tags":["stable-diffusion","latent-diffusion","generative-models","image-synthesis"]},{"type":"paper","title":"Feature Pyramid Networks for Object Detection","description":"Feature pyramids are a basic component in recognition systems for detecting objects at different scales. This paper exploits the inherent multi-scale, pyramidal hierarchy of deep convolutional network","url":"/en/topics/computer-vision/papers","topicSlug":"computer-vision","topicTitle":"Computer Vision","tags":["fpn","object-detection","multi-scale"]},{"type":"paper","title":"Segment Anything","description":"We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to","url":"/en/topics/computer-vision/papers","topicSlug":"computer-vision","topicTitle":"Computer Vision","tags":["sam","segmentation","foundation-models","zero-shot"]},{"type":"quiz","title":"Quiz — Computer Vision","description":"10 questions to test your knowledge on Computer Vision","url":"/en/topics/computer-vision/quiz","topicSlug":"computer-vision","topicTitle":"Computer Vision","level":"intermediaire"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Computer Vision","url":"/en/topics/computer-vision/papers/feature-pyramid-networks-for-object-detection","topicSlug":"computer-vision","topicTitle":"Computer Vision"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Computer Vision","url":"/en/topics/computer-vision/papers/high-resolution-image-synthesis-with-latent-diffusion-models","topicSlug":"computer-vision","topicTitle":"Computer Vision"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Computer Vision","url":"/en/topics/computer-vision/papers/mask-r-cnn","topicSlug":"computer-vision","topicTitle":"Computer Vision"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Computer Vision","url":"/en/topics/computer-vision/papers/segment-anything","topicSlug":"computer-vision","topicTitle":"Computer Vision"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Computer Vision","url":"/en/topics/computer-vision/papers/u-net-convolutional-networks-for-biomedical-image-segmentation","topicSlug":"computer-vision","topicTitle":"Computer Vision"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Computer Vision","url":"/en/topics/computer-vision/papers/very-deep-convolutional-networks-for-large-scale-image-recognition","topicSlug":"computer-vision","topicTitle":"Computer Vision"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Computer Vision","url":"/en/topics/computer-vision/papers/you-only-look-once-unified-real-time-object-detection","topicSlug":"computer-vision","topicTitle":"Computer Vision"},{"type":"topic","title":"Deep Learning","description":"Le deep learning (apprentissage profond) est un sous-domaine du machine learning basé sur les **réseaux de neurones artificiels** à plusieurs couches. L'idée : empiler des couches de neurones qui tran","url":"/en/topics/deep-learning","topicSlug":"deep-learning","topicTitle":"Deep Learning","level":"debutant"},{"type":"paper","title":"ImageNet Classification with Deep Convolutional Neural Networks","description":"We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achiev","url":"/en/topics/deep-learning/papers","topicSlug":"deep-learning","topicTitle":"Deep Learning","tags":["cnn","imagenet","classification","alexnet"]},{"type":"paper","title":"Deep Residual Learning for Image Recognition","description":"Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly re","url":"/en/topics/deep-learning/papers","topicSlug":"deep-learning","topicTitle":"Deep Learning","tags":["resnet","residual-connections","cnn","imagenet"]},{"type":"paper","title":"Generative Adversarial Networks","description":"We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a dis","url":"/en/topics/deep-learning/papers","topicSlug":"deep-learning","topicTitle":"Deep Learning","tags":["gan","generative-models","unsupervised-learning"]},{"type":"paper","title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale","description":"While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. We show that a pure transformer applied d","url":"/en/topics/deep-learning/papers","topicSlug":"deep-learning","topicTitle":"Deep Learning","tags":["vit","transformers","computer-vision","classification"]},{"type":"paper","title":"Denoising Diffusion Probabilistic Models","description":"We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results ","url":"/en/topics/deep-learning/papers","topicSlug":"deep-learning","topicTitle":"Deep Learning","tags":["diffusion-models","generative-models","image-synthesis"]},{"type":"paper","title":"Learning Representations by Back-Propagating Errors","description":"We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure o","url":"/en/topics/deep-learning/papers","topicSlug":"deep-learning","topicTitle":"Deep Learning","tags":["backpropagation","neural-networks","foundational"]},{"type":"paper","title":"Long Short-Term Memory","description":"Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's ","url":"/en/topics/deep-learning/papers","topicSlug":"deep-learning","topicTitle":"Deep Learning","tags":["lstm","rnn","sequence-modeling"]},{"type":"quiz","title":"Quiz — Deep Learning","description":"5 questions to test your knowledge on Deep Learning","url":"/en/topics/deep-learning/quiz","topicSlug":"deep-learning","topicTitle":"Deep Learning","level":"debutant"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Deep Learning","url":"/en/topics/deep-learning/papers/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale","topicSlug":"deep-learning","topicTitle":"Deep Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Deep Learning","url":"/en/topics/deep-learning/papers/deep-residual-learning-for-image-recognition","topicSlug":"deep-learning","topicTitle":"Deep Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Deep Learning","url":"/en/topics/deep-learning/papers/denoising-diffusion-probabilistic-models","topicSlug":"deep-learning","topicTitle":"Deep Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Deep Learning","url":"/en/topics/deep-learning/papers/generative-adversarial-networks","topicSlug":"deep-learning","topicTitle":"Deep Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Deep Learning","url":"/en/topics/deep-learning/papers/imagenet-classification-with-deep-convolutional-neural-networks","topicSlug":"deep-learning","topicTitle":"Deep Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Deep Learning","url":"/en/topics/deep-learning/papers/learning-representations-by-back-propagating-errors","topicSlug":"deep-learning","topicTitle":"Deep Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Deep Learning","url":"/en/topics/deep-learning/papers/long-short-term-memory","topicSlug":"deep-learning","topicTitle":"Deep Learning"},{"type":"topic","title":"Generative Models","description":"Les modèles génératifs sont une famille de modèles de deep learning dont l'objectif est d'apprendre la distribution sous-jacente des données pour en générer de nouvelles. Contrairement aux modèles dis","url":"/en/topics/generative-models","topicSlug":"generative-models","topicTitle":"Generative Models","level":"intermediaire"},{"type":"paper","title":"Pre to Post-Treatment Glioblastoma MRI Prediction using a Latent Diffusion Model","description":"Glioblastoma (GBM) is an aggressive primary brain tumor with a median survival of approximately 15 months. In clinical practice, the Stupp protocol serves as the standard first-line treatment. However","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.CV","cs.AI"]},{"type":"paper","title":"DiM: Distilling Dataset into Generative Model","description":"Dataset distillation reduces the network training cost by synthesizing small and informative datasets from large-scale ones. Despite the success of the recent dataset distillation algorithms, three dr","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.CV"]},{"type":"paper","title":"Operationalizing Specifications, In Addition to Test Sets for Evaluating Constrained Generative Models","description":"In this work, we present some recommendations on the evaluation of state-of-the-art generative models for constrained generation tasks. The progress on generative models has been rapid in recent years","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.HC","cs.CL","cs.CV","cs.CY"]},{"type":"paper","title":"Quaternion Generative Adversarial Networks","description":"Latest Generative Adversarial Networks (GANs) are gathering outstanding results through a large-scale training, thus employing models composed of millions of parameters requiring extensive computation","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.LG","cs.AI","cs.CV","eess.IV"]},{"type":"paper","title":"Generative Models in Decision Making: A Survey","description":"In recent years, the exceptional performance of generative models in generative tasks has sparked significant interest in their integration into decision-making processes. Due to their ability to hand","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.LG","cs.AI"]},{"type":"paper","title":"Improving Model Compatibility of Generative Adversarial Networks by Boundary Calibration","description":"Generative Adversarial Networks (GANs) is a powerful family of models that learn an underlying distribution to generate synthetic data. Many existing studies of GANs focus on improving the realness of","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.LG"]},{"type":"paper","title":"A 3D generative model of pathological multi-modal MR images and segmentations","description":"Generative modelling and synthetic data can be a surrogate for real medical imaging datasets, whose scarcity and difficulty to share can be a nuisance when delivering accurate deep learning models for","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["eess.IV","cs.CV"]},{"type":"paper","title":"DDxT: Deep Generative Transformer Models for Differential Diagnosis","description":"Differential Diagnosis (DDx) is the process of identifying the most likely medical condition among the possible pathologies through the process of elimination based on evidence. An automated process t","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.LG","cs.AI"]},{"type":"paper","title":"Happy People -- Image Synthesis as Black-Box Optimization Problem in the Discrete Latent Space of Deep Generative Models","description":"In recent years, optimization in the learned latent space of deep generative models has been successfully applied to black-box optimization problems such as drug design, image generation or neural arc","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.CV"]},{"type":"paper","title":"Memory Efficient Diffusion Probabilistic Models via Patch-based Generation","description":"Diffusion probabilistic models have been successful in generating high-quality and diverse images. However, traditional models, whose input and output are high-resolution images, suffer from excessive","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.CV","cs.LG"]},{"type":"paper","title":"Case Study of GAI for Generating Novel Images for Real-World Embroidery","description":"In this paper, we present a case study exploring the potential use of Generative Artificial Intelligence (GAI) to address the real-world need of making the design of embroiderable art patterns more ac","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.HC","cs.CY"]},{"type":"paper","title":"Auto-FEDUS: Autoregressive Generative Modeling of Doppler Ultrasound Signals from Fetal Electrocardiograms","description":"Fetal health monitoring through one-dimensional Doppler ultrasound (DUS) signals offers a cost-effective and accessible approach that is increasingly gaining interest. Despite its potential, the devel","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.LG"]},{"type":"paper","title":"The Informed Sampler: A Discriminative Approach to Bayesian Inference in Generative Computer Vision Models","description":"Computer vision is hard because of a large variability in lighting, shape, and texture; in addition the image signal is non-additive due to occlusion. Generative models promised to account for this va","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.CV","cs.LG","stat.ML"]},{"type":"paper","title":"Bayesian Image Reconstruction using Deep Generative Models","description":"Machine learning models are commonly trained end-to-end and in a supervised setting, using paired (input, output) data. Examples include recent super-resolution methods that train on pairs of (low-res","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.CV","cs.LG","cs.NE","eess.IV","stat.ML"]},{"type":"paper","title":"MolGAN: An implicit generative model for small molecular graphs","description":"Deep generative models for graph-structured data offer a new angle on the problem of chemical synthesis: by optimizing differentiable models that directly generate molecular graphs, it is possible to ","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["stat.ML","cs.LG"]},{"type":"paper","title":"Manipulating and Mitigating Generative Model Biases without Retraining","description":"Text-to-image (T2I) generative models have gained increased popularity in the public domain. While boasting impressive user-guided generative abilities, their black-box nature exposes users to intenti","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.CV","cs.AI"]},{"type":"paper","title":"Approximate Query Processing using Deep Generative Models","description":"Data is generated at an unprecedented rate surpassing our ability to analyze them. The database community has pioneered many novel techniques for Approximate Query Processing (AQP) that could give app","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.DB","cs.LG"]},{"type":"paper","title":"Cognitive Architecture Toward Common Ground Sharing Among Humans and Generative AIs: Trial on Model-Model Interactions in Tangram Naming Task","description":"For generative AIs to be trustworthy, establishing transparent common grounding with humans is essential. As a preparation toward human-model common grounding, this study examines the process of model","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.AI"]},{"type":"paper","title":"Evaluating Generative Models for Tabular Data: Novel Metrics and Benchmarking","description":"Generative models have revolutionized multiple domains, yet their application to tabular data remains underexplored. Evaluating generative models for tabular data presents unique challenges due to str","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["cs.LG"]},{"type":"paper","title":"Brain Imaging Generation with Latent Diffusion Models","description":"Deep neural networks have brought remarkable breakthroughs in medical image analysis. However, due to their data-hungry nature, the modest dataset sizes in medical imaging projects might be hindering ","url":"/en/topics/generative-models/papers","topicSlug":"generative-models","topicTitle":"Generative Models","tags":["eess.IV","cs.CV","q-bio.QM"]},{"type":"quiz","title":"Quiz — Generative Models","description":"10 questions to test your knowledge on Generative Models","url":"/en/topics/generative-models/quiz","topicSlug":"generative-models","topicTitle":"Generative Models","level":"intermediaire"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/a-3d-generative-model-of-pathological-multi-modal-mr-images-and-segmentations","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/approximate-query-processing-using-deep-generative-models","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/auto-fedus-autoregressive-generative-modeling-of-doppler-ultrasound-signals-from-fetal-electrocardiograms","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/bayesian-image-reconstruction-using-deep-generative-models","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/brain-imaging-generation-with-latent-diffusion-models","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/case-study-of-gai-for-generating-novel-images-for-real-world-embroidery","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/cognitive-architecture-toward-common-ground-sharing-among-humans-and-generative-ais-trial-on-model-model-interactions-in-tangram-naming-task","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/ddxt-deep-generative-transformer-models-for-differential-diagnosis","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/dim-distilling-dataset-into-generative-model","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/evaluating-generative-models-for-tabular-data-novel-metrics-and-benchmarking","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/generative-models-in-decision-making-a-survey","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/happy-people-image-synthesis-as-black-box-optimization-problem-in-the-discrete-latent-space-of-deep-generative-models","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/improving-model-compatibility-of-generative-adversarial-networks-by-boundary-calibration","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/manipulating-and-mitigating-generative-model-biases-without-retraining","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/memory-efficient-diffusion-probabilistic-models-via-patch-based-generation","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/molgan-an-implicit-generative-model-for-small-molecular-graphs","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/operationalizing-specifications-in-addition-to-test-sets-for-evaluating-constrained-generative-models","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/pre-to-post-treatment-glioblastoma-mri-prediction-using-a-latent-diffusion-model","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/quaternion-generative-adversarial-networks","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Generative Models","url":"/en/topics/generative-models/papers/the-informed-sampler-a-discriminative-approach-to-bayesian-inference-in-generative-computer-vision-models","topicSlug":"generative-models","topicTitle":"Generative Models"},{"type":"topic","title":"Graph Neural Networks","description":"Les Graph Neural Networks (GNNs) sont une famille de réseaux de neurones conçus pour opérer directement sur des données structurées en graphes. Contrairement aux images (grilles) ou au texte (séquence","url":"/en/topics/graph-neural-networks","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks","level":"avance"},{"type":"paper","title":"MECCH: Metapath Context Convolution-based Heterogeneous Graph Neural Networks","description":"Heterogeneous graph neural networks (HGNNs) were proposed for representation learning on structural data with multiple types of nodes and edges. To deal with the performance degradation issue when HGN","url":"/en/topics/graph-neural-networks/papers","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks","tags":["cs.LG"]},{"type":"paper","title":"Transformers are Graph Neural Networks","description":"We establish connections between the Transformer architecture, originally introduced for natural language processing, and Graph Neural Networks (GNNs) for representation learning on graphs. We show ho","url":"/en/topics/graph-neural-networks/papers","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks","tags":["cs.LG","cs.AI"]},{"type":"paper","title":"Fast and Deep Graph Neural Networks","description":"We address the efficiency issue for the construction of a deep graph neural network (GNN). The approach exploits the idea of representing each input graph as a fixed point of a dynamical system (imple","url":"/en/topics/graph-neural-networks/papers","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks","tags":["cs.LG","math.DS","stat.ML"]},{"type":"paper","title":"Modern graph neural networks do worse than classical greedy algorithms in solving combinatorial optimization problems like maximum independent set","description":"The recent work ``Combinatorial Optimization with Physics-Inspired Graph Neural Networks'' [Nat Mach Intell 4 (2022) 367] introduces a physics-inspired unsupervised Graph Neural Network (GNN) to solve","url":"/en/topics/graph-neural-networks/papers","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks","tags":["cs.LG","cond-mat.dis-nn","cs.AI","math.OC"]},{"type":"paper","title":"Missing Data Imputation with Adversarially-trained Graph Convolutional Networks","description":"Missing data imputation (MDI) is a fundamental problem in many scientific disciplines. Popular methods for MDI use global statistics computed from the entire data set (e.g., the feature-wise medians),","url":"/en/topics/graph-neural-networks/papers","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks","tags":["cs.LG","stat.ML"]},{"type":"quiz","title":"Quiz — Graph Neural Networks","description":"15 questions to test your knowledge on Graph Neural Networks","url":"/en/topics/graph-neural-networks/quiz","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks","level":"avance"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Graph Neural Networks","url":"/en/topics/graph-neural-networks/papers/fast-and-deep-graph-neural-networks","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Graph Neural Networks","url":"/en/topics/graph-neural-networks/papers/mecch-metapath-context-convolution-based-heterogeneous-graph-neural-networks","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Graph Neural Networks","url":"/en/topics/graph-neural-networks/papers/missing-data-imputation-with-adversarially-trained-graph-convolutional-networks","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Graph Neural Networks","url":"/en/topics/graph-neural-networks/papers/modern-graph-neural-networks-do-worse-than-classical-greedy-algorithms-in-solving-combinatorial-optimization-problems-like-maximum-independent-set","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Graph Neural Networks","url":"/en/topics/graph-neural-networks/papers/transformers-are-graph-neural-networks","topicSlug":"graph-neural-networks","topicTitle":"Graph Neural Networks"},{"type":"topic","title":"Large Language Models","description":"Les Large Language Models (LLMs) sont des modèles de deep learning massivement paramétrés, entraînés sur d'immenses corpus textuels pour comprendre et générer du langage naturel. Basés sur l'architect","url":"/en/topics/large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models","level":"avance"},{"type":"paper","title":"Enhancing Human-Like Responses in Large Language Models","description":"This paper explores the advancements in making large language models (LLMs) more human-like. We focus on techniques that enhance natural language understanding, conversational coherence, and emotional","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI"]},{"type":"paper","title":"Is Self-knowledge and Action Consistent or Not: Investigating Large Language Model's Personality","description":"In this study, we delve into the validity of conventional personality questionnaires in capturing the human-like personality traits of Large Language Models (LLMs). Our objective is to assess the cong","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.CY"]},{"type":"paper","title":"Large Language Models Lack Understanding of Character Composition of Words","description":"Large language models (LLMs) have demonstrated remarkable performances on a wide range of natural language tasks. Yet, LLMs' successes have been largely restricted to tasks concerning words, sentences","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL"]},{"type":"paper","title":"Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models","description":"This research critically navigates the intricate landscape of AI deception, concentrating on deceptive behaviours of Large Language Models (LLMs). My objective is to elucidate this issue, examine the ","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI"]},{"type":"paper","title":"Self-Cognition in Large Language Models: An Exploratory Study","description":"While Large Language Models (LLMs) have achieved remarkable success across various applications, they also raise concerns regarding self-cognition. In this paper, we perform a pioneering study to expl","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI"]},{"type":"paper","title":"Making Large Language Models Better Reasoners with Alignment","description":"Reasoning is a cognitive process of using evidence to reach a sound conclusion. The reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general i","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI","cs.LG"]},{"type":"paper","title":"Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models","description":"The age of social media is rife with memes. Understanding and detecting harmful memes pose a significant challenge due to their implicit meaning that is not explicitly conveyed through the surface tex","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL"]},{"type":"paper","title":"A Critical Review of Causal Reasoning Benchmarks for Large Language Models","description":"Numerous benchmarks aim to evaluate the capabilities of Large Language Models (LLMs) for causal inference and reasoning. However, many of them can likely be solved through the retrieval of domain know","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.LG","cs.CL"]},{"type":"paper","title":"All Languages Matter: On the Multilingual Safety of Large Language Models","description":"Safety lies at the core of developing and deploying large language models (LLMs). However, previous safety benchmarks only concern the safety in one language, e.g. the majority language in the pretrai","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI"]},{"type":"paper","title":"Classifying German Language Proficiency Levels Using Large Language Models","description":"Assessing language proficiency is essential for education, as it enables instruction tailored to learners needs. This paper investigates the use of Large Language Models (LLMs) for automatically class","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI"]},{"type":"paper","title":"A Survey on Multimodal Large Language Models","description":"Recently, Multimodal Large Language Model (MLLM) represented by GPT-4V has been a new rising research hotspot, which uses powerful Large Language Models (LLMs) as a brain to perform multimodal tasks. ","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CV","cs.AI","cs.CL","cs.LG"]},{"type":"paper","title":"Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models","description":"A pivotal advancement in the progress of large language models (LLMs) is the emergence of the Mixture-of-Experts (MoE) LLMs. Compared to traditional LLMs, MoE LLMs can achieve higher performance with ","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI","cs.LG"]},{"type":"paper","title":"Attacks on Third-Party APIs of Large Language Models","description":"Large language model (LLM) services have recently begun offering a plugin ecosystem to interact with third-party API services. This innovation enhances the capabilities of LLMs, but it also introduces","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CR","cs.AI","cs.CL","cs.CY"]},{"type":"paper","title":"TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models","description":"Despite Multi-modal Large Language Models (MM-LLMs) have made exciting strides recently, they are still struggling to efficiently model the interactions among multi-modal inputs and the generation in ","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI"]},{"type":"paper","title":"Large Language Models in Ambulatory Devices for Home Health Diagnostics: A case study of Sickle Cell Anemia Management","description":"This study investigates the potential of an ambulatory device that incorporates Large Language Models (LLMs) in cadence with other specialized ML models to assess anemia severity in sickle cell patien","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL"]},{"type":"paper","title":"PruneVid: Visual Token Pruning for Efficient Video Large Language Models","description":"In this paper, we introduce PruneVid, a visual token pruning method designed to enhance the efficiency of multi-modal video understanding. Large Language Models (LLMs) have shown promising performance","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CV"]},{"type":"paper","title":"Reinforcement Learning Meets Large Language Models: A Survey of Advancements and Applications Across the LLM Lifecycle","description":"In recent years, training methods centered on Reinforcement Learning (RL) have markedly enhanced the reasoning and alignment performance of Large Language Models (LLMs), particularly in understanding ","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL"]},{"type":"paper","title":"LAraBench: Benchmarking Arabic AI with Large Language Models","description":"Recent advancements in Large Language Models (LLMs) have significantly influenced the landscape of language and speech research. Despite this progress, these models lack specific benchmarking against ","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI"]},{"type":"paper","title":"Scaling Behavior of Machine Translation with Large Language Models under Prompt Injection Attacks","description":"Large Language Models (LLMs) are increasingly becoming the preferred foundation platforms for many Natural Language Processing tasks such as Machine Translation, owing to their quality often comparabl","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL"]},{"type":"paper","title":"Emissions and Performance Trade-off Between Small and Large Language Models","description":"The advent of Large Language Models (LLMs) has raised concerns about their enormous carbon footprint, starting with energy-intensive training and continuing through repeated inference. This study inve","url":"/en/topics/large-language-models/papers","topicSlug":"large-language-models","topicTitle":"Large Language Models","tags":["cs.CL","cs.AI","cs.CY","cs.LG"]},{"type":"quiz","title":"Quiz — Large Language Models","description":"15 questions to test your knowledge on Large Language Models","url":"/en/topics/large-language-models/quiz","topicSlug":"large-language-models","topicTitle":"Large Language Models","level":"avance"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/a-critical-review-of-causal-reasoning-benchmarks-for-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/a-survey-on-multimodal-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/all-languages-matter-on-the-multilingual-safety-of-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/attacks-on-third-party-apis-of-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/beneath-the-surface-unveiling-harmful-memes-with-multimodal-reasoning-distilled-from-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/classifying-german-language-proficiency-levels-using-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/emissions-and-performance-trade-off-between-small-and-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/enhancing-human-like-responses-in-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/is-self-knowledge-and-action-consistent-or-not-investigating-large-language-models-personality","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/larabench-benchmarking-arabic-ai-with-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/large-language-models-in-ambulatory-devices-for-home-health-diagnostics-a-case-study-of-sickle-cell-anemia-management","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/large-language-models-lack-understanding-of-character-composition-of-words","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/making-large-language-models-better-reasoners-with-alignment","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/not-all-experts-are-equal-efficient-expert-pruning-and-skipping-for-mixture-of-experts-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/prunevid-visual-token-pruning-for-efficient-video-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/reinforcement-learning-meets-large-language-models-a-survey-of-advancements-and-applications-across-the-llm-lifecycle","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/scaling-behavior-of-machine-translation-with-large-language-models-under-prompt-injection-attacks","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/self-cognition-in-large-language-models-an-exploratory-study","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/teal-tokenize-and-embed-all-for-multi-modal-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Large Language Models","url":"/en/topics/large-language-models/papers/unmasking-the-shadows-of-ai-investigating-deceptive-capabilities-in-large-language-models","topicSlug":"large-language-models","topicTitle":"Large Language Models"},{"type":"topic","title":"Machine Learning","description":"Le machine learning (apprentissage automatique) est une branche de l'intelligence artificielle qui permet aux systèmes d'apprendre à partir de données sans être explicitement programmés. Plutôt que de","url":"/en/topics/machine-learning","topicSlug":"machine-learning","topicTitle":"Machine Learning","level":"debutant"},{"type":"paper","title":"Attention Is All You Need","description":"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["transformers","attention","nlp","deep-learning"]},{"type":"paper","title":"A Few Useful Things to Know About Machine Learning","description":"Machine learning algorithms can figure out how to perform important tasks by generalizing from examples. This is often feasible and cost-effective where manual programming is not. As more data becomes","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["survey","fundamentals","best-practices"]},{"type":"paper","title":"Random Forests","description":"Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The g","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["ensemble-methods","classification","regression"]},{"type":"paper","title":"Support-Vector Networks","description":"The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["svm","classification","kernel-methods"]},{"type":"paper","title":"Gradient-Based Learning Applied to Document Recognition","description":"Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient-based learning technique. Given an appropriate network architecture, gradien","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["cnn","deep-learning","computer-vision","backpropagation"]},{"type":"paper","title":"An Introduction to Statistical Learning","description":"This book provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["textbook","statistics","fundamentals","supervised-learning"]},{"type":"paper","title":"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift","description":"Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the trai","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["optimization","deep-learning","training"]},{"type":"paper","title":"Adam: A Method for Stochastic Optimization","description":"We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to impl","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["optimization","gradient-descent","deep-learning"]},{"type":"paper","title":"Dropout: A Simple Way to Prevent Neural Networks from Overfitting","description":"Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. We propose dropout, a technique for addressin","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["regularization","deep-learning","overfitting"]},{"type":"paper","title":"XGBoost: A Scalable Tree Boosting System","description":"Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientis","url":"/en/topics/machine-learning/papers","topicSlug":"machine-learning","topicTitle":"Machine Learning","tags":["boosting","ensemble-methods","classification","regression"]},{"type":"quiz","title":"Quiz — Machine Learning","description":"5 questions to test your knowledge on Machine Learning","url":"/en/topics/machine-learning/quiz","topicSlug":"machine-learning","topicTitle":"Machine Learning","level":"debutant"},{"type":"paper-summary","title":"Résumé vulgarisé : A Few Useful Things to Know About Machine Learning","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/a-few-useful-things-to-know-about-machine-learning","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/adam-a-method-for-stochastic-optimization","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/an-introduction-to-statistical-learning","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"paper-summary","title":"Résumé vulgarisé du paper : Attention Is All You Need","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/attention-is-all-you-need","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/dropout-a-simple-way-to-prevent-neural-networks-from-overfitting","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/gradient-based-learning-applied-to-document-recognition","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/random-forests","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/support-vector-networks","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Machine Learning","url":"/en/topics/machine-learning/papers/xgboost-a-scalable-tree-boosting-system","topicSlug":"machine-learning","topicTitle":"Machine Learning"},{"type":"topic","title":"Mathématiques pour l'Intelligence Artificielle","description":"Les mathématiques sont le langage dans lequel l'intelligence artificielle est écrite. De l'algèbre linéaire qui structure les données, au calcul différentiel qui entraîne les réseaux de neurones, en p","url":"/en/topics/mathematics-for-ai","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","level":"debutant"},{"type":"paper","title":"The Modern Mathematics of Deep Learning","description":"We describe the new field of mathematical analysis of deep learning. This field emerged around a list of research questions that were not answered within the classical framework of learning theory. Th","url":"/en/topics/mathematics-for-ai/papers","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","tags":["cs.LG","stat.ML"]},{"type":"paper","title":"Learn to Accumulate Evidence from All Training Samples: Theory and Practice","description":"Evidential deep learning, built upon belief theory and subjective logic, offers a principled and computationally efficient way to turn a deterministic neural network uncertainty-aware. The resultant e","url":"/en/topics/mathematics-for-ai/papers","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","tags":["cs.LG","cs.AI","cs.CV"]},{"type":"paper","title":"Deep Learning and Computational Physics (Lecture Notes)","description":"These notes were compiled as lecture notes for a course developed and taught at the University of the Southern California. They should be accessible to a typical engineering graduate student with a st","url":"/en/topics/mathematics-for-ai/papers","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","tags":["cs.LG","math-ph"]},{"type":"paper","title":"Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation","description":"Evidential deep learning (EDL) models, based on Subjective Logic, introduce a principled and computationally efficient way to make deterministic neural networks uncertainty-aware. The resulting eviden","url":"/en/topics/mathematics-for-ai/papers","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","tags":["cs.LG","cs.AI"]},{"type":"paper","title":"Quadratic number of nodes is sufficient to learn a dataset via gradient descent","description":"We prove that if an activation function satisfies some mild conditions and number of neurons in a two-layered fully connected neural network with this activation function is beyond a certain threshold","url":"/en/topics/mathematics-for-ai/papers","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","tags":["math.OC","cs.LG","math.ST"]},{"type":"paper","title":"Beyond NTK with Vanilla Gradient Descent: A Mean-Field Analysis of Neural Networks with Polynomial Width, Samples, and Time","description":"Despite recent theoretical progress on the non-convex optimization of two-layer neural networks, it is still an open question whether gradient descent on neural networks without unnatural modification","url":"/en/topics/mathematics-for-ai/papers","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","tags":["cs.LG"]},{"type":"paper","title":"Survey Descent: A Multipoint Generalization of Gradient Descent for Nonsmooth Optimization","description":"For strongly convex objectives that are smooth, the classical theory of gradient descent ensures linear convergence relative to the number of gradient evaluations. An analogous nonsmooth theory is cha","url":"/en/topics/mathematics-for-ai/papers","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","tags":["math.OC","cs.CG","cs.LG","math.NA"]},{"type":"paper","title":"Learning Active Subspaces and Discovering Important Features with Gaussian Radial Basis Functions Neural Networks","description":"Providing a model that achieves a strong predictive performance and is simultaneously interpretable by humans is one of the most difficult challenges in machine learning research due to the conflictin","url":"/en/topics/mathematics-for-ai/papers","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","tags":["cs.LG","cs.AI","cs.NE","stat.ML"]},{"type":"quiz","title":"Quiz — Mathématiques pour l'Intelligence Artificielle","description":"5 questions to test your knowledge on Mathématiques pour l'Intelligence Artificielle","url":"/en/topics/mathematics-for-ai/quiz","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle","level":"debutant"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Mathématiques pour l'Intelligence Artificielle","url":"/en/topics/mathematics-for-ai/papers/beyond-ntk-with-vanilla-gradient-descent-a-mean-field-analysis-of-neural-networks-with-polynomial-width-samples-and-time","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Mathématiques pour l'Intelligence Artificielle","url":"/en/topics/mathematics-for-ai/papers/deep-learning-and-computational-physics-lecture-notes","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Mathématiques pour l'Intelligence Artificielle","url":"/en/topics/mathematics-for-ai/papers/generalized-regularized-evidential-deep-learning-models-theory-and-comprehensive-evaluation","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Mathématiques pour l'Intelligence Artificielle","url":"/en/topics/mathematics-for-ai/papers/learn-to-accumulate-evidence-from-all-training-samples-theory-and-practice","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Mathématiques pour l'Intelligence Artificielle","url":"/en/topics/mathematics-for-ai/papers/learning-active-subspaces-and-discovering-important-features-with-gaussian-radial-basis-functions-neural-networks","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Mathématiques pour l'Intelligence Artificielle","url":"/en/topics/mathematics-for-ai/papers/quadratic-number-of-nodes-is-sufficient-to-learn-a-dataset-via-gradient-descent","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Mathématiques pour l'Intelligence Artificielle","url":"/en/topics/mathematics-for-ai/papers/survey-descent-a-multipoint-generalization-of-gradient-descent-for-nonsmooth-optimization","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Mathématiques pour l'Intelligence Artificielle","url":"/en/topics/mathematics-for-ai/papers/the-modern-mathematics-of-deep-learning","topicSlug":"mathematics-for-ai","topicTitle":"Mathématiques pour l'Intelligence Artificielle"},{"type":"topic","title":"Natural Language Processing (NLP)","description":"Le traitement automatique du langage naturel (NLP) est le domaine de l'IA qui permet aux machines de **comprendre, interpréter et générer du langage humain**. C'est le champ qui a produit les chatbots","url":"/en/topics/natural-language-processing","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)","level":"intermediaire"},{"type":"paper","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding","description":"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed t","url":"/en/topics/natural-language-processing/papers","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)","tags":["bert","transformers","pre-training","language-models"]},{"type":"paper","title":"Language Models are Few-Shot Learners","description":"We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. We trai","url":"/en/topics/natural-language-processing/papers","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)","tags":["gpt-3","few-shot","language-models","scaling"]},{"type":"paper","title":"Efficient Estimation of Word Representations in Vector Space","description":"We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task,","url":"/en/topics/natural-language-processing/papers","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)","tags":["word2vec","word-embeddings","representation-learning"]},{"type":"paper","title":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks","description":"Large pre-trained language models have been shown to store factual knowledge in their parameters. However, their ability to access and precisely manipulate knowledge is still limited. We explore a gen","url":"/en/topics/natural-language-processing/papers","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)","tags":["rag","retrieval","knowledge","language-models"]},{"type":"paper","title":"Sequence to Sequence Learning with Neural Networks","description":"Deep Neural Networks are powerful models that have achieved excellent performance on difficult learning tasks. We present a general end-to-end approach to sequence learning that makes minimal assumpti","url":"/en/topics/natural-language-processing/papers","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)","tags":["seq2seq","lstm","machine-translation","encoder-decoder"]},{"type":"paper","title":"LLaMA: Open and Efficient Foundation Language Models","description":"We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art mod","url":"/en/topics/natural-language-processing/papers","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)","tags":["llama","open-source","language-models","foundation-models"]},{"type":"paper","title":"Neural Machine Translation by Jointly Learning to Align and Translate","description":"Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neur","url":"/en/topics/natural-language-processing/papers","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)","tags":["attention","machine-translation","seq2seq"]},{"type":"quiz","title":"Quiz — Natural Language Processing (NLP)","description":"10 questions to test your knowledge on Natural Language Processing (NLP)","url":"/en/topics/natural-language-processing/quiz","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)","level":"intermediaire"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Natural Language Processing (NLP)","url":"/en/topics/natural-language-processing/papers/bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Natural Language Processing (NLP)","url":"/en/topics/natural-language-processing/papers/efficient-estimation-of-word-representations-in-vector-space","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Natural Language Processing (NLP)","url":"/en/topics/natural-language-processing/papers/language-models-are-few-shot-learners","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Natural Language Processing (NLP)","url":"/en/topics/natural-language-processing/papers/llama-open-and-efficient-foundation-language-models","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Natural Language Processing (NLP)","url":"/en/topics/natural-language-processing/papers/neural-machine-translation-by-jointly-learning-to-align-and-translate","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Natural Language Processing (NLP)","url":"/en/topics/natural-language-processing/papers/retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Natural Language Processing (NLP)","url":"/en/topics/natural-language-processing/papers/sequence-to-sequence-learning-with-neural-networks","topicSlug":"natural-language-processing","topicTitle":"Natural Language Processing (NLP)"},{"type":"topic","title":"Reinforcement Learning","description":"L'apprentissage par renforcement (RL) est un paradigme du machine learning dans lequel un **agent** apprend à prendre des décisions en interagissant avec un **environnement**. À chaque étape, l'agent ","url":"/en/topics/reinforcement-learning","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning","level":"intermediaire"},{"type":"paper","title":"Playing Atari with Deep Reinforcement Learning","description":"We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, ","url":"/en/topics/reinforcement-learning/papers","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning","tags":["dqn","atari","deep-rl"]},{"type":"paper","title":"Mastering the Game of Go with Deep Neural Networks and Tree Search","description":"The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. ","url":"/en/topics/reinforcement-learning/papers","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning","tags":["alphago","mcts","deep-rl","go"]},{"type":"paper","title":"Proximal Policy Optimization Algorithms","description":"We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a surrogate objective func","url":"/en/topics/reinforcement-learning/papers","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning","tags":["ppo","policy-gradient","deep-rl"]},{"type":"paper","title":"Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm","description":"The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptat","url":"/en/topics/reinforcement-learning/papers","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning","tags":["alphazero","self-play","mcts","deep-rl"]},{"type":"paper","title":"Training Language Models to Follow Instructions with Human Feedback","description":"Making language models bigger does not inherently make them better at following a user's intent. Large language models can generate outputs that are untruthful, toxic, or simply not helpful. We show a","url":"/en/topics/reinforcement-learning/papers","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning","tags":["rlhf","alignment","llm","instruction-following"]},{"type":"paper","title":"Continuous Control with Deep Reinforcement Learning","description":"We adapt the ideas underlying the success of Deep Q-Network to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operat","url":"/en/topics/reinforcement-learning/papers","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning","tags":["ddpg","actor-critic","continuous-control","deep-rl"]},{"type":"paper","title":"Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model","description":"Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. We introduce MuZero, a new approach to model-based reinforcement lear","url":"/en/topics/reinforcement-learning/papers","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning","tags":["muzero","model-based","planning","deep-rl"]},{"type":"quiz","title":"Quiz — Reinforcement Learning","description":"10 questions to test your knowledge on Reinforcement Learning","url":"/en/topics/reinforcement-learning/quiz","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning","level":"intermediaire"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Reinforcement Learning","url":"/en/topics/reinforcement-learning/papers/continuous-control-with-deep-reinforcement-learning","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Reinforcement Learning","url":"/en/topics/reinforcement-learning/papers/mastering-atari-go-chess-and-shogi-by-planning-with-a-learned-model","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Reinforcement Learning","url":"/en/topics/reinforcement-learning/papers/mastering-chess-and-shogi-by-self-play-with-a-general-reinforcement-learning-algorithm","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Reinforcement Learning","url":"/en/topics/reinforcement-learning/papers/mastering-the-game-of-go-with-deep-neural-networks-and-tree-search","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Reinforcement Learning","url":"/en/topics/reinforcement-learning/papers/playing-atari-with-deep-reinforcement-learning","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Reinforcement Learning","url":"/en/topics/reinforcement-learning/papers/proximal-policy-optimization-algorithms","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Reinforcement Learning","url":"/en/topics/reinforcement-learning/papers/training-language-models-to-follow-instructions-with-human-feedback","topicSlug":"reinforcement-learning","topicTitle":"Reinforcement Learning"},{"type":"topic","title":"Statistiques pour la Data Science","description":"Les statistiques sont le socle mathématique de la data science et du machine learning. Elles fournissent les outils pour collecter, analyser, interpréter et présenter des données. Comprendre les stati","url":"/en/topics/statistics","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","level":"debutant"},{"type":"paper","title":"Changing Data Sources in the Age of Machine Learning for Official Statistics","description":"Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data scie","url":"/en/topics/statistics/papers","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","tags":["stat.ML","cs.LG"]},{"type":"paper","title":"Statistical Inference, Learning and Models in Big Data","description":"The need for new methods to deal with big data is a common theme in most scientific fields, although its definition tends to vary with the context. Statistical ideas are an essential part of this, and","url":"/en/topics/statistics/papers","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","tags":["stat.ML","cs.LG"]},{"type":"paper","title":"Active learning for data streams: a survey","description":"Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting","url":"/en/topics/statistics/papers","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","tags":["stat.ML","cs.LG","stat.ME"]},{"type":"paper","title":"The Sample Complexity of Simple Binary Hypothesis Testing","description":"The sample complexity of simple binary hypothesis testing is the smallest number of i.i.d. samples required to distinguish between two distributions p and q in either: (i) the prior-free setting, with","url":"/en/topics/statistics/papers","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","tags":["math.ST","cs.IT","stat.ML"]},{"type":"paper","title":"Two-sample Bayesian Nonparametric Hypothesis Testing","description":"In this article we describe Bayesian nonparametric procedures for two-sample hypothesis testing. Namely, given two sets of samples, we wish to evaluate the evidence for the null hypothesis H0: F1 ≡ F2","url":"/en/topics/statistics/papers","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","tags":["stat.ME"]},{"type":"paper","title":"Approximate Inference for Fully Bayesian Gaussian Process Regression","description":"Learning in Gaussian Process models occurs through the adaptation of hyperparameters of the mean and the covariance function. The classical approach entails maximizing the marginal likelihood yielding","url":"/en/topics/statistics/papers","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","tags":["stat.ML","cs.LG"]},{"type":"paper","title":"Normalizing Flow Regression for Bayesian Inference with Offline Likelihood Evaluations","description":"Bayesian inference with computationally expensive likelihood evaluations remains a significant challenge in many scientific domains. We propose normalizing flow regression (NFR), a novel offline infer","url":"/en/topics/statistics/papers","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","tags":["stat.ML","cs.LG"]},{"type":"paper","title":"Bayesian Nonparametric Weighted Sampling Inference","description":"It has historically been a challenge to perform Bayesian inference in a design-based survey context. The present paper develops a Bayesian model for sampling inference in the presence of inverse-proba","url":"/en/topics/statistics/papers","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","tags":["stat.ME","stat.AP","stat.CO"]},{"type":"quiz","title":"Quiz — Statistiques pour la Data Science","description":"5 questions to test your knowledge on Statistiques pour la Data Science","url":"/en/topics/statistics/quiz","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science","level":"debutant"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Statistiques pour la Data Science","url":"/en/topics/statistics/papers/active-learning-for-data-streams-a-survey","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Statistiques pour la Data Science","url":"/en/topics/statistics/papers/approximate-inference-for-fully-bayesian-gaussian-process-regression","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Statistiques pour la Data Science","url":"/en/topics/statistics/papers/bayesian-nonparametric-weighted-sampling-inference","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Statistiques pour la Data Science","url":"/en/topics/statistics/papers/changing-data-sources-in-the-age-of-machine-learning-for-official-statistics","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Statistiques pour la Data Science","url":"/en/topics/statistics/papers/normalizing-flow-regression-for-bayesian-inference-with-offline-likelihood-evaluations","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Statistiques pour la Data Science","url":"/en/topics/statistics/papers/statistical-inference-learning-and-models-in-big-data","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Statistiques pour la Data Science","url":"/en/topics/statistics/papers/the-sample-complexity-of-simple-binary-hypothesis-testing","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Statistiques pour la Data Science","url":"/en/topics/statistics/papers/two-sample-bayesian-nonparametric-hypothesis-testing","topicSlug":"statistics","topicTitle":"Statistiques pour la Data Science"},{"type":"topic","title":"Transfer Learning","description":"Le transfer learning (apprentissage par transfert) est une technique qui consiste à réutiliser un modèle pré-entraîné sur une tâche source (souvent à grande échelle) pour l'adapter à une tâche cible d","url":"/en/topics/transfer-learning","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","level":"intermediaire"},{"type":"paper","title":"Federated and Transfer Learning: A Survey on Adversaries and Defense Mechanisms","description":"The advent of federated learning has facilitated large-scale data exchange amongst machine learning models while maintaining privacy. Despite its brief history, federated learning is rapidly evolving ","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG","cs.AI","cs.CR","cs.CV","cs.DC"]},{"type":"paper","title":"Transfer Learning Toolkit: Primers and Benchmarks","description":"The transfer learning toolkit wraps the codes of 17 transfer learning models and provides integrated interfaces, allowing users to use those models by calling a simple function. It is easy for primary","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG","stat.ML"]},{"type":"paper","title":"Predicting concentration levels of air pollutants by transfer learning and recurrent neural network","description":"Air pollution (AP) poses a great threat to human health, and people are paying more attention than ever to its prediction. Accurate prediction of AP helps people to plan for their outdoor activities a","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG","cs.NE","physics.ao-ph"]},{"type":"paper","title":"Transfer Learning and Organic Computing for Autonomous Vehicles","description":"Autonomous Vehicles(AV) are one of the brightest promises of the future which would help cut down fatalities and improve travel time while working in harmony. Autonomous vehicles will face with challe","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG","cs.RO","stat.ML"]},{"type":"paper","title":"Transfer Learning with Pre-trained Conditional Generative Models","description":"Transfer learning is crucial in training deep neural networks on new target tasks. Current transfer learning methods always assume at least one of (i) source and target task label spaces overlap, (ii)","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG","cs.AI","stat.ML"]},{"type":"paper","title":"Transferability in Deep Learning: A Survey","description":"The success of deep learning algorithms generally depends on large-scale data, while humans appear to have inherent ability of knowledge transfer, by recognizing and applying relevant knowledge from p","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG"]},{"type":"paper","title":"How good are variational autoencoders at transfer learning?","description":"Variational autoencoders (VAEs) are used for transfer learning across various research domains such as music generation or medical image analysis. However, there is no principled way to assess before ","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG"]},{"type":"paper","title":"Transfer Learning for Kernel-based Regression","description":"In recent years, transfer learning has garnered significant attention. Its ability to leverage knowledge from related studies to improve generalization performance in a target study has made it highly","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["stat.ML","cs.LG","stat.ME"]},{"type":"paper","title":"G5: A Universal GRAPH-BERT for Graph-to-Graph Transfer and Apocalypse Learning","description":"The recent GRAPH-BERT model introduces a new approach to learning graph representations merely based on the attention mechanism. GRAPH-BERT provides an opportunity for transferring pre-trained models ","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG","cs.NE","cs.SI","stat.ML"]},{"type":"paper","title":"Transfer Learning between Motor Imagery Datasets using Deep Learning -- Validation of Framework and Comparison of Datasets","description":"We present a simple deep learning-based framework commonly used in computer vision and demonstrate its effectiveness for cross-dataset transfer learning in mental imagery decoding tasks that are commo","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.CV","cs.AI","cs.HC","cs.LG"]},{"type":"paper","title":"Transfer learning in hybrid classical-quantum neural networks","description":"We extend the concept of transfer learning, widely applied in modern machine learning algorithms, to the emerging context of hybrid neural networks composed of classical and quantum elements. We propo","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["quant-ph","cs.LG","stat.ML"]},{"type":"paper","title":"Transfer Learning for Causal Effect Estimation","description":"We present a Transfer Causal Learning (TCL) framework when target and source domains share the same covariate/feature spaces, aiming to improve causal effect estimation accuracy in limited data.","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG","math.ST","stat.ME","stat.ML"]},{"type":"paper","title":"Communication-Efficient and Privacy-Preserving Feature-based Federated Transfer Learning","description":"Federated learning has attracted growing interest as it preserves the clients' privacy. As a variant of federated learning, federated transfer learning utilizes the knowledge from similar tasks and th","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG"]},{"type":"paper","title":"Efficient Transfer Learning via Joint Adaptation of Network Architecture and Weight","description":"Transfer learning can boost the performance on the target task by leveraging the knowledge of the source domain. Recent works in neural architecture search (NAS), especially one-shot NAS, can aid tran","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.CV"]},{"type":"paper","title":"Transfer Representation Learning with TSK Fuzzy System","description":"Transfer learning can address the learning tasks of unlabeled data in the target domain by leveraging plenty of labeled data from a different but related source domain. A core issue in transfer learni","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.LG","cs.AI"]},{"type":"paper","title":"Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation","description":"Despite the remarkable success of Deep RL in learning control policies from raw pixels, the resulting models do not generalize. We demonstrate that a trained agent fails completely when facing small v","url":"/en/topics/transfer-learning/papers","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","tags":["cs.CV","cs.AI","cs.LG"]},{"type":"quiz","title":"Quiz — Transfer Learning","description":"10 questions to test your knowledge on Transfer Learning","url":"/en/topics/transfer-learning/quiz","topicSlug":"transfer-learning","topicTitle":"Transfer Learning","level":"intermediaire"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/communication-efficient-and-privacy-preserving-feature-based-federated-transfer-learning","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/efficient-transfer-learning-via-joint-adaptation-of-network-architecture-and-weight","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/federated-and-transfer-learning-a-survey-on-adversaries-and-defense-mechanisms","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/g5-a-universal-graph-bert-for-graph-to-graph-transfer-and-apocalypse-learning","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/how-good-are-variational-autoencoders-at-transfer-learning","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/predicting-concentration-levels-of-air-pollutants-by-transfer-learning-and-recurrent-neural-network","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transfer-learning-and-organic-computing-for-autonomous-vehicles","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transfer-learning-between-motor-imagery-datasets-using-deep-learning-validation-of-framework-and-comparison-of-datasets","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transfer-learning-for-causal-effect-estimation","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transfer-learning-for-kernel-based-regression","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transfer-learning-for-related-reinforcement-learning-tasks-via-image-to-image-translation","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transfer-learning-in-hybrid-classical-quantum-neural-networks","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transfer-learning-toolkit-primers-and-benchmarks","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transfer-learning-with-pre-trained-conditional-generative-models","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transfer-representation-learning-with-tsk-fuzzy-system","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Transfer Learning","url":"/en/topics/transfer-learning/papers/transferability-in-deep-learning-a-survey","topicSlug":"transfer-learning","topicTitle":"Transfer Learning"},{"type":"topic","title":"Vision-Language Models","description":"Les Vision-Language Models (VLMs) sont des modèles multimodaux capables de comprendre et de raisonner conjointement sur des images et du texte. Ils combinent un encodeur visuel (souvent un Vision Tran","url":"/en/topics/vision-language-models","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","level":"avance"},{"type":"paper","title":"Object Detection with Multimodal Large Vision-Language Models: An In-depth Review","description":"The fusion of language and vision in large vision-language models (LVLMs) has revolutionized deep learning-based object detection by enhancing adaptability, contextual reasoning, and generalization be","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.AI","cs.CL"]},{"type":"paper","title":"VLP: A Survey on Vision-Language Pre-training","description":"In the past few years, the emergence of pre-training models has brought uni-modal fields such as computer vision (CV) and natural language processing (NLP) to a new era. Substantial works have shown t","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.CL"]},{"type":"paper","title":"Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models","description":"Building state-of-the-art Vision-Language Models (VLMs) with strong captioning capabilities typically necessitates training on billions of high-quality image-text pairs, requiring millions of GPU hour","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV"]},{"type":"paper","title":"Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions","description":"The advent of Large Language Models (LLMs) has significantly reshaped the trajectory of the AI revolution. Nevertheless, these LLMs exhibit a notable limitation, as they are primarily adept at process","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.AI","cs.CL"]},{"type":"paper","title":"Benchmarking Vision Language Models on German Factual Data","description":"Similar to LLMs, the development of vision language models is mainly driven by English datasets and models trained in English and Chinese language, whereas support for other languages, even those cons","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CL"]},{"type":"paper","title":"Vision-Language Pre-training: Basics, Recent Advances, and Future Trends","description":"This paper surveys vision-language pre-training (VLP) methods for multimodal intelligence that have been developed in the last few years. We group these approaches into three categories: ($i$) VLP for","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.CL"]},{"type":"paper","title":"Behavioral Bias of Vision-Language Models: A Behavioral Finance View","description":"Large Vision-Language Models (LVLMs) evolve rapidly as Large Language Models (LLMs) was equipped with vision modules to create more human-like models. However, we should carefully evaluate their appli","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CL","cs.AI"]},{"type":"paper","title":"Evaluation and Enhancement of Semantic Grounding in Large Vision-Language Models","description":"Large Vision-Language Models (LVLMs) offer remarkable benefits for a variety of vision-language tasks. However, a challenge hindering their application in real-world scenarios, particularly regarding ","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.CL"]},{"type":"paper","title":"LVLM-eHub: A Comprehensive Evaluation Benchmark for Large Vision-Language Models","description":"Large Vision-Language Models (LVLMs) have recently played a dominant role in multimodal vision-language learning. Despite the great success, it lacks a holistic evaluation of their efficacy. This pape","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.AI"]},{"type":"paper","title":"Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP","description":"Mechanistic interpretability seeks to understand the neural mechanisms that enable specific behaviors in Large Language Models (LLMs) by leveraging causality-based methods. While these approaches have","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CL","cs.AI","cs.CV"]},{"type":"paper","title":"Towards Vision-Language-Garment Models for Web Knowledge Garment Understanding and Generation","description":"Multimodal foundation models have demonstrated strong generalization, yet their ability to transfer knowledge to specialized domains such as garment generation remains underexplored. We introduce VLG,","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV"]},{"type":"paper","title":"Explaining Vision and Language through Graphs of Events in Space and Time","description":"Artificial Intelligence makes great advances today and starts to bridge the gap between vision and language. However, we are still far from understanding, explaining and controlling explicitly the vis","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.AI","cs.CL","cs.CV"]},{"type":"paper","title":"On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations","description":"Vision-Language Models (VLMs) are increasingly used as perceptual modules for visual content reasoning, including through captioning and DeepFake detection. In this work, we expose a critical vulnerab","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV"]},{"type":"paper","title":"How do language models learn facts? Dynamics, curricula and hallucinations","description":"Large language models accumulate vast knowledge during pre-training, yet the dynamics governing this acquisition remain poorly understood. This work investigates the learning dynamics of language mode","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CL","cs.LG"]},{"type":"paper","title":"Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation","description":"Vision-Language Model (VLM) have gained widespread adoption in Open-Vocabulary (OV) object detection and segmentation tasks. Despite they have shown promise on OV-related tasks, their effectiveness in","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.AI"]},{"type":"paper","title":"Evaluating Vision-Language Models as Evaluators in Path Planning","description":"Despite their promise to perform complex reasoning, large language models (LLMs) have been shown to have limited effectiveness in end-to-end planning. This has inspired an intriguing question: if thes","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.CL"]},{"type":"paper","title":"Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models","description":"Vision-language models (VLMs) frequently generate hallucinated content plausible but incorrect claims about image content. We propose a training-free self-correction framework enabling VLMs to iterati","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.AI","cs.CL","cs.LG"]},{"type":"paper","title":"Coordinated Robustness Evaluation Framework for Vision-Language Models","description":"Vision-language models, which integrate computer vision and natural language processing capabilities, have demonstrated significant advancements in tasks such as image captioning and visual question a","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.AI","cs.CL","cs.LG"]},{"type":"paper","title":"Multi-Frame, Lightweight & Efficient Vision-Language Models for Question Answering in Autonomous Driving","description":"Vision-Language Models (VLMs) and Multi-Modal Language models (MMLMs) have become prominent in autonomous driving research, as these models can provide interpretable textual reasoning and responses fo","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.AI"]},{"type":"paper","title":"Distilling Large Vision-Language Model with Out-of-Distribution Generalizability","description":"Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impract","url":"/en/topics/vision-language-models/papers","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","tags":["cs.CV","cs.AI","cs.CL","cs.LG"]},{"type":"quiz","title":"Quiz — Vision-Language Models","description":"15 questions to test your knowledge on Vision-Language Models","url":"/en/topics/vision-language-models/quiz","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models","level":"avance"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/behavioral-bias-of-vision-language-models-a-behavioral-finance-view","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/benchmarking-vision-language-models-on-german-factual-data","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/coordinated-robustness-evaluation-framework-for-vision-language-models","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/distilling-large-vision-language-model-with-out-of-distribution-generalizability","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/evaluating-vision-language-models-as-evaluators-in-path-planning","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/evaluation-and-enhancement-of-semantic-grounding-in-large-vision-language-models","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/explaining-vision-and-language-through-graphs-of-events-in-space-and-time","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/exploring-the-frontier-of-vision-language-models-a-survey-of-current-methodologies-and-future-directions","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/how-do-language-models-learn-facts-dynamics-curricula-and-hallucinations","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/lvlm-ehub-a-comprehensive-evaluation-benchmark-for-large-vision-language-models","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/multi-frame-lightweight-efficient-vision-language-models-for-question-answering-in-autonomous-driving","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/object-detection-with-multimodal-large-vision-language-models-an-in-depth-review","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/on-the-reliability-of-vision-language-models-under-adversarial-frequency-domain-perturbations","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/toward-more-reliable-artificial-intelligence-reducing-hallucinations-in-vision-language-models","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/towards-vision-language-garment-models-for-web-knowledge-garment-understanding-and-generation","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/towards-vision-language-mechanistic-interpretability-a-causal-tracing-tool-for-blip","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/vision-language-model-for-object-detection-and-segmentation-a-review-and-evaluation","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/vision-language-pre-training-basics-recent-advances-and-future-trends","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/vision-language-vision-auto-encoder-scalable-knowledge-distillation-from-diffusion-models","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"},{"type":"paper-summary","title":"# Contexte","description":"Simplified summary — Vision-Language Models","url":"/en/topics/vision-language-models/papers/vlp-a-survey-on-vision-language-pre-training","topicSlug":"vision-language-models","topicTitle":"Vision-Language Models"}]